{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151fc62-9f29-4eaa-b4f3-c02af12b83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from exod.utils.path import data_raw, data_processed\n",
    "\n",
    "# Load Events list\n",
    "event_file = '../data/processed/0001730201/P0001730201PNU002PIEVLI0000_FILT.fits'\n",
    "\n",
    "instrument = fits.open(event_file)[0].header['INSTRUME'] # ['EMOS1', 'EMOS2', 'EPN']\n",
    "tab        = Table.read(event_file, hdu=1)\n",
    "df         = tab.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6800aa-0977-40a9-8b34-aece24d83a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only 1 CCD and set the start time to 0\n",
    "df = df[df['CCDNR'] == 4]\n",
    "df['TIME'] = df['TIME'] - df['TIME'].min()\n",
    "\n",
    "# Only include columns we need\n",
    "df = df[['TIME', 'RAWX', 'RAWY', 'PI']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef5f40-bdff-4f4e-a69f-59bcd6545231",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bin_size = 20\n",
    "box_size   = 3\n",
    "x_max = 69\n",
    "y_max = 203\n",
    "\n",
    "t_0, t_f   = df['TIME'].min(), df['TIME'].max()\n",
    "t_bins     = t_bins = np.arange(t_0, t_f + t_bin_size, t_bin_size)\n",
    "x_bins     = np.arange(0, x_max+box_size, box_size)\n",
    "y_bins     = np.arange(0, y_max+box_size, box_size)\n",
    "\n",
    "N_t_bins   = len(t_bins)\n",
    "N_y_bins   = len(y_bins)\n",
    "N_x_bins   = len(x_bins)\n",
    "\n",
    "cube_size = N_t_bins * N_y_bins * N_x_bins\n",
    "print(N_t_bins, N_y_bins, N_x_bins, cube_size)\n",
    "\n",
    "\n",
    "# Group photons into time windows, and boxes\n",
    "df['RAWX_GROUP'] = pd.cut(df['RAWX'], bins=x_bins)\n",
    "df['RAWY_GROUP'] = pd.cut(df['RAWY'], bins=y_bins)\n",
    "df['XY_BOX']     = df['RAWX_GROUP'].astype(str) + '_' + df['RAWY_GROUP'].astype(str)\n",
    "df['TIME_BIN']   = pd.cut(df['TIME'], bins=t_bins, right=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac5f6d-860b-4f59-8acf-c745ace89ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['RAWX_GROUP'].isna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ea992-42b6-4e7e-b6af-2e852dd020e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a5e6d-082a-4c40-a548-d6c533a101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c15b9-7c5c-498d-adad-1b59d8d9b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb463c06-c495-4de7-b02b-6197454d765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Extract unique boxes\n",
    "unique_boxes = df['XY_BOX'].unique()\n",
    "\n",
    "# Perform DBSCAN clustering for each unique box\n",
    "for box in tqdm(unique_boxes):\n",
    "    # Select data for the current box\n",
    "    box_data = df[df['XY_BOX'] == box][['TIME']]\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    box_data_scaled = scaler.fit_transform(box_data)\n",
    "\n",
    "    # Apply DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=0.05, min_samples=10)\n",
    "    labels = dbscan.fit_predict(box_data_scaled)\n",
    "\n",
    "    # Add the cluster labels to the original DataFrame\n",
    "    df.loc[df['XY_BOX'] == box, 'CLUSTER_LABEL'] = labels\n",
    "\n",
    "df[['XY_BOX', 'TIME', 'CLUSTER_LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c6c5c-7064-4c73-884b-e72ea73aa14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLUSTER_LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f8437-6929-4430-b5b4-021a7edee5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "plt.scatter(df['RAWX'], df['RAWY'], s=0.001)\n",
    "for i in range(1,7):\n",
    "    df_lab = df[df['CLUSTER_LABEL'] == i]\n",
    "    plt.scatter(df_lab['RAWX'], df_lab['RAWY'], marker='+', label=f'{i}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c92f51-a216-4062-8981-51ecb4f7656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(1,7):\n",
    "    df_lab = df[df['CLUSTER_LABEL'] == i]\n",
    "    ax.scatter(df_lab['RAWX'], df_lab['RAWY'], df_lab['TIME'], marker='.', label=f'{i}', s=3)\n",
    "    \n",
    "ax.set_xlabel('RAWX')\n",
    "ax.set_ylabel('RAWY')\n",
    "ax.set_zlabel('TIME')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfae45-d715-414f-bd92-334245394b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of photons in each time_window + bin combination\n",
    "# Using observed=True  will only return those groups that had values\n",
    "# Using observed=False will return all combinations even if they did not have counts\n",
    "df_sub = df[['TIME_BIN','XY_BOX', 'PI']]\n",
    "box_counts = df_sub.groupby(['TIME_BIN', 'XY_BOX'], observed=True).count().reset_index()\n",
    "box_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b17519-3a8a-4551-be35-f567dffd3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result back with the original DataFrame based on 'TIME_BIN' and 'XY_BOX'\n",
    "result_df = pd.merge(df, box_counts, on=['TIME_BIN', 'XY_BOX'], how='right', suffixes=('_original', '_count'))\n",
    "result_df = result_df.drop(columns=['PI_count'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44bfb8-0066-4ba6-8426-f9f0fd99e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X, Y low and high values for each photon\n",
    "box_counts_split = box_counts['XY_BOX'].str.extract(r'\\((\\d+), (\\d+)\\]\\_\\((\\d+), (\\d+)\\]').astype(int)\n",
    "box_counts_split.columns = ['X_LO', 'X_HI', 'Y_LO', 'Y_HI']\n",
    "box_counts_split['VAL'] = box_counts['PI'] # Add column with number of detected photons\n",
    "box_counts_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d8424-8bff-4999-8586-125e9802d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_arrays = []\n",
    "for time_bin in box_counts['TIME_BIN'].unique():\n",
    "    image_size = (y_max, x_max)\n",
    "    image_array = np.zeros(image_size, dtype=int)\n",
    "    \n",
    "    box_counts_time_bin = box_counts_split[box_counts['TIME_BIN'] == time_bin]\n",
    "    for index, row in box_counts_time_bin.iterrows():\n",
    "        image_array[row['Y_LO']:row['Y_HI'], row['X_LO']:row['X_HI']] = row['VAL']\n",
    "    image_arrays.append(image_array)\n",
    "    #plt.title(time_bin)\n",
    "    #plt.imshow(image_array)\n",
    "    #plt.show()\n",
    "image_arrays = np.array(image_arrays)\n",
    "\n",
    "print(f'Number of image frames={len(image_arrays)}')\n",
    "\n",
    "\n",
    "c_max = np.max(image_arrays, axis=0)\n",
    "c_median = np.median(image_arrays, axis=0)\n",
    "c_min = np.min(image_arrays, axis=0)\n",
    "c_median_nonzero = np.where(c_median == 0, 1, c_median)\n",
    "V = np.maximum(c_max - c_median, c_median - c_min)\n",
    "\n",
    "plt.imshow(V,  interpolation='none') # norm=LogNorm(),\n",
    "#plt.xlim(0,64)\n",
    "#plt.ylim(3,200)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c8da5-b942-40c3-9cff-da62cfb201d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (y_max, x_max)\n",
    "V_array = np.zeros(image_size, dtype=int)\n",
    "hit_array = np.zeros(image_size, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f25f8-19c9-4212-8299-6cf0ac766470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in box_counts_split.iterrows():\n",
    "    V_array[row['Y_LO']:row['Y_HI'], row['X_LO']:row['X_HI']] += row['VAL']\n",
    "    hit_array[row['Y_LO']:row['Y_HI'], row['X_LO']:row['X_HI']] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c943ff-9739-46d4-826c-9bbd8f87191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].set_title('Summed energies')\n",
    "m1 = ax[0].imshow(V_array, norm=LogNorm(), interpolation='none', origin='lower', cmap='hot')\n",
    "plt.colorbar(m1, ax=ax[0])\n",
    "ax[1].set_title('Summed Counts')\n",
    "m2 = ax[1].imshow(hit_array, norm=LogNorm(), interpolation='none', origin='lower', cmap='hot')\n",
    "plt.colorbar(m2, ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05308a3-686c-4da2-b2f7-f9c47fe68810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46c4d9-1e2d-4109-a712-e7d6f782071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4789f-ff0a-4e63-9c1b-c6331aebba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844be04-fcdc-41f4-a194-915d51fca4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate 1D data with two clusters and some noise\n",
    "X, _ = make_blobs(n_samples=300, centers=[[2], [8]], cluster_std=1.0, random_state=42)\n",
    "\n",
    "# Add some noise\n",
    "noise = np.random.uniform(low=0, high=12, size=(30, 1))\n",
    "X = np.concatenate([X, noise])\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(X)\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(X, np.zeros_like(X), label='Original Data')\n",
    "\n",
    "# Plot the clustered data\n",
    "unique_labels = np.unique(labels)\n",
    "for label in unique_labels:\n",
    "    if label == -1:\n",
    "        plt.scatter(X[labels == label], np.zeros_like(X[labels == label]), label='Noise', marker='x', c='black')\n",
    "    else:\n",
    "        plt.scatter(X[labels == label], np.zeros_like(X[labels == label]), label=f'Cluster {label + 1}')\n",
    "\n",
    "plt.title('DBSCAN Clustering of 1D Data')\n",
    "plt.xlabel('Data Points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419f4d6-ba00-45b4-8434-336ee066cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18705a0a-b109-41ec-a38b-c1d959bc8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_samp = np.random.poisson(lam=0.01, size=100000)\n",
    "poi_idx  = np.where(poi_samp>0)[0]\n",
    "poi_toa  = poi_idx * 73.4E-3\n",
    "poi_toa  = poi_toa.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09814405-88b1-4201-b535-0861fe1d8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1D data with two clusters and some noise\n",
    "X, _ = make_blobs(n_samples=1000, centers=[[2000], [4000]], cluster_std=10)\n",
    "\n",
    "noise = np.random.uniform(low=0, high=25000, size=(10,1))\n",
    "X_sum = np.concatenate([X, poi_toa])\n",
    "# Plot the original data\n",
    "plt.scatter(X_sum, np.zeros_like(X_sum), label='Data', marker='.')\n",
    "plt.scatter(X, np.zeros_like(X), label='Burst', marker='.')\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=10)\n",
    "labels = dbscan.fit_predict(X)\n",
    "\n",
    "# Plot the clustered data\n",
    "unique_labels = np.unique(labels)\n",
    "for i, label in enumerate(unique_labels):\n",
    "    if label == -1:\n",
    "        plt.scatter(X[labels == label], i+np.zeros_like(X[labels == label]), label='Noise', marker='x', c='black')\n",
    "    else:\n",
    "        plt.scatter(X[labels == label], i+np.zeros_like(X[labels == label]), label=f'Cluster {label + 1}')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50434f-0cc8-41e9-84fb-f299529bcf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac03f7b-6eb9-45a5-9f4a-0c58cb0aa17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
